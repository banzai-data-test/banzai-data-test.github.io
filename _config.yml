Title: Automated Data Pipeline with GitHub Pages CSV Upload

Description:
This project demonstrates an end-to-end data pipeline that begins with uploading a CSV file through a GitHub Pages site, processes the data, and finally visualizes it using Metabase. The pipeline consists of the following steps:

Upload a CSV file to the GitHub Pages site.
Ingest the CSV data using a Flask app running on Heroku, which processes and cleans the data.
Load the processed data into Google Sheets.
Sync the data to Snowflake using Fivetran.
Transform the data using dbt.
Visualize the data with Metabase.
The project leverages a bash script that automates the creation of a Dockerfile, Flask app, and deployment to Heroku. The bash script sets up the necessary configurations, creates files, and performs necessary git operations to set up a new GitHub repository. The script is designed to be executable and can be run from any project directory.

The bash file is available on this repo so that you can quickly and efficiently create a powerful data pipeline to connect to your visualization platform of choice.
  
theme: jekyll-theme-minimal
google_analytics: UA-000000-0 # your Google Analytics tracking ID here
